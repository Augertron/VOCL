const char *cl_source_reduction =
"#ifdef SINGLE_PRECISION\n"
"#define FPTYPE float\n"
"#elif K_DOUBLE_PRECISION\n"
"#pragma OPENCL EXTENSION cl_khr_fp64: enable\n"
"#define FPTYPE double\n"
"#elif AMD_DOUBLE_PRECISION\n"
"#pragma OPENCL EXTENSION cl_amd_fp64: enable\n"
"#define FPTYPE double\n"
"#endif\n"
"\n"
"__kernel void\n"
"reduce(__global const FPTYPE *g_idata, __global FPTYPE *g_odata,\n"
"       __local FPTYPE* sdata, const unsigned int n)\n"
"{\n"
"    const unsigned int tid = get_local_id(0);\n"
"    unsigned int i = (get_group_id(0)*(get_local_size(0)*2)) + tid;\n"
"    const unsigned int gridSize = get_local_size(0)*2*get_num_groups(0);\n"
"    const unsigned int blockSize = get_local_size(0);\n"
"\n"
"    sdata[tid] = 0;\n"
"\n"
"    // Reduce multiple elements per thread, strided by grid size\n"
"    while (i < n)\n"
"    {         \n"
"        sdata[tid] += g_idata[i] + g_idata[i+blockSize];\n"
"        i += gridSize;\n"
"    } \n"
"    barrier(CLK_LOCAL_MEM_FENCE);\n"
"\n"
"    // do reduction in shared mem\n"
"    for (unsigned int s = blockSize / 2; s > 0; s >>= 1)\n"
"    {\n"
"        if (tid < s)\n"
"        {\n"
"            sdata[tid] += sdata[tid + s];\n"
"        }\n"
"        barrier(CLK_LOCAL_MEM_FENCE);\n"
"    }\n"
"\n"
"    // Write result back to global memory\n"
"    if (tid == 0)\n"
"    {\n"
"        g_odata[get_group_id(0)] = sdata[0];\n"
"    }\n"
"}\n"
"\n"
"\n"
"// Currently, CPUs on Snow Leopard only support a work group size of 1\n"
"// So, we have a separate version of the kernel which doesn't use\n"
"// local memory. This version is only used when the maximum\n"
"// supported local group size is 1.\n"
"__kernel void\n"
"reduceNoLocal(__global FPTYPE *g_idata, __global FPTYPE *g_odata,\n"
"       unsigned int n)\n"
"{\n"
"    FPTYPE sum = 0.0f;\n"
"    for (int i = 0; i < n; i++)\n"
"    {\n"
"        sum += g_idata[i];\n"
"    }\n"
"    g_odata[0] = sum;\n"
"}\n"
;
